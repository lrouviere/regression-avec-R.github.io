---
title: "Chapitre 11 : régression logistique"
layout: default
output: 
  html_document:
    css: styles.css
    toc: true
    toc_float: true
    layout: default
#  html_document:
#    toc: true
#    toc_depth: 3
#  github_document:
#    toc: true
#    toc_depth: 3
---



## Exercice 1

  1. A
  2. A
  3. B
  4. A
  5. A
  6. A
  7. B
  8. A
  9. C
  10. D
  11. A, B
  12. C
  
  
## Exercice 2

1. 
```{r}
n <- 100
set.seed(48967365)
X <- sample(c("A","B","C"),100,replace=TRUE)
Y <- rep(0,n)
set.seed(487365)
Y[X=="A"] <- rbinom(sum(X=="A"),size=1,prob=0.95)
set.seed(4878365)
Y[X=="B"] <- rbinom(sum(X=="B"),size=1,prob=0.95)
set.seed(4653965)
Y[X=="C"] <- rbinom(sum(X=="C"),size=1,prob=0.05)
Y <- factor(Y)
donnees<-data.frame(Y,X)
```

2. 
```{r}
model1 <- glm(Y~X,data=donnees,family=binomial)
summary(model1)
```

On obtient les résultats du **test de Wald** sur la nullité des paramètres $\beta_0,\beta_2$ et $\beta_3$.

3.
```{r}
model2 <- glm(Y~C(X,base=3),data=donnees,family=binomial)
summary(model2)
```
On obtient les résultats du **test de Wald** sur la nullité des paramètres $\beta_0,\beta_1$ et $\beta_2$.

4. On remarque que dans **model1** on accepte la nullité de $\beta_2$ alors qu'on la rejette dans **model2**. Ceci est logique dans la mesure où ces tests dépendent de la contrainte identifiante choisie. Dans **model1** le test de nullité de $\beta_2$ permet de vérifier si $B$ à un effet similaire à $A$ sur $Y$. Dans **model2**, on compare l'effet de $B$ à celui de $C$. On peut donc conclure $A$ et $B$ ont des effets proches sur $Y$ alors que $B$ et $C$ ont un impact différent. Ceci est logique vu la façon dont les données ont été générées.

5. Tester l'effet global de $X$ sur $Y$ revient à tester si les coefficients $\beta_1,\beta_2$ et $\beta_3$ sont égaux, ce qui, compte tenu des contraintes revient à considérer les hypothèses nulles :
  * $\beta_2=\beta_3=0$ dans **model1** ;
  * $\beta_1=\beta_2=0$ dans **model2**.
  
On peut effectuer les tests de **Wald** ou du **rapport de vraisemblance**. On obtient les résultats du **rapport de vraisemblance** avec :

```{r message=FALSE, warning=FALSE}
library(car)
Anova(model1,type=3,test.statistic="LR")
Anova(model2,type=3,test.statistic="LR")
```


On remarque ici que ces deux tests sont identiques : ils ne dépendent pas de la contrainte identifiante choisie.

## Exercice 3

1.
```{r}
set.seed(1234)
X <- c(runif(50,-1,0),runif(50,0,1))
set.seed(5678)
Y <- c(rep(0,50),rep(1,50))
df <- data.frame(X,Y)
```


2.
```{r}
beta <- seq(0,100,by=0.01)
log_vrais <- function(X,Y,beta){
  LV <- rep(0,length(beta))
  for (i in 1:length(beta)){
    Pbeta <- exp(beta[i]*X)/(1+exp(beta[i]*X))
    LV[i] <- sum(Y*X*beta[i]-log(1+exp(X*beta[i])))
#    gradln[i] <- t(Xb)%*%(Yb-Pbeta)
  }
  return(LV)
}
LL <- log_vrais(X,Y,beta)
plot(beta,LL,type="l")
```

3.
```{r}
model <- glm(Y~X-1,data=df,family="binomial")
model$coef
```
On obtient un avertissement qui nous dit que l'algorithme d'optimisation n'a pas convergé.

4.

```{r}
Y1 <- Y;Y1[1] <- 1
LL1 <- log_vrais(X,Y1,beta)
plot(beta,LL1,type="l")
model1 <- glm(Y1~X-1,family="binomial")
model1$coef
```


## Exercice 4


## Exercice 5

On importe les données
```{r}
panne <- read.table("panne.txt",header=T)
head(panne)
```


1. La commande
```{r}
model <- glm(etat~.,data=panne,family=binomial)
model
```

ajuste le modèle

$$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\beta_0+\beta_1x_1+\beta_2\mathsf{1}_{x_2=B}+\beta_3\mathsf{1}_{x_2=C}$$

où $x_1$ et $x_2$ désigne respectivement les variables **age** et **marque**. On obtient les estimateurs avec
```{r}
coef(model)
```

2. 

Il s'agit des tests de Wald pour tester l'effet des variables dans le modèle. Pour l'effet de marque, on va par exemple tester 
$$H_0:\beta_2=\beta_3=0\quad\text{contre}\quad H_1:\beta_2\neq 0\text{ ou }\beta_3\neq 0.$$
Sous $H_0$ la statistique de Wald suit une loi du $\chi^2$ à 4-2=2 degrés de liberté. Pour le test de la variable **age** le nombre de degrés de liberté manquant est 1. On retrouve cela dans la sortie

```{r}
library(car)
Anova(model,type=3,test.statistic="Wald")
```

3. Il s'agit cett fois du test du rapport de vraisemblance. Les degrés de liberté manquants sont identiques.

```{r}
Anova(model,type=3,test.statistic="LR")
```



4. 
  a). Le modèle s'écrit
  $$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\beta_0+\beta_1\mathsf{1}_{x_2=A}+\beta_2\mathsf{1}_{x_2=B}.$$

  b). Le modèle ajusté ici est
    $$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\gamma_0+\gamma_1\mathsf{1}_{x_2=B}+\gamma_2\mathsf{1}_{x_2=C}.$$

Par identification on a
$$\begin{cases}
\beta_0+\beta_1=\gamma_0 \\
\beta_0+\beta_2=\gamma_0+\gamma_1 \\
\beta_0=\gamma_0+\gamma_2 \\
\end{cases}
\Longleftrightarrow
\begin{cases}
\beta_0=\gamma_0+\gamma_2 \\
\beta_1=-\gamma_2 \\
\beta_2=\gamma_1-\gamma_2 \\
\end{cases}
\Longrightarrow
\begin{cases}
\widehat\beta_0=-0.92 \\
\widehat\beta_1=1.48 \\
\widehat\beta_2=1.05 \\
\end{cases}$$



On peut retrouver ces résultats avec

```{r}
glm(etat~C(marque,base=3),data=panne,family="binomial")
```


5. Il y a interaction si l'age agit différemment sur la panne en fonction de la marque.

6.




